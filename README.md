#To execute remotely
- log in to https://portal.azure.com/ 
- select "azure databricks"
- select existing "resource group" (you should see at least 1)
- press 'launch workspace in the bottom'. you should see 'databricks user interface'

Within databricks User Interface
- click 'create cluster' (import spark-config.json)
- Wait until cluster is created
- Create notebook, select created cluster
- copy content of jupiter playground (spark & ml separately)